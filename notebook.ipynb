{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendendo Tensorflow\n",
    "Esse notebook visa abordar dois assuntos em específico do Tensorflow:\n",
    "- Diferentes tuners de hiperparâmetros\n",
    "- Diferentes tipos de Callbacks e suas utilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bibliotecas  e dados a serem utilizados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o dataset Fashion MNIST\n",
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tuners\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "O Grid Search padrão. Contempla todas as combinações de hiperparâmetros definidas pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.GridSearch(model_builder,\n",
    "                      objective='val_accuracy',\n",
    "                      max_trials=5,\n",
    "                      directory='grid_search',\n",
    "                      project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 20s]\n",
      "val_accuracy: 0.8756666779518127\n",
      "\n",
      "Best val_accuracy So Far: 0.8756666779518127\n",
      "Total elapsed time: 00h 01m 44s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 64 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=5, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperband\n",
    "O Hyperband é um algoritmo de busca de hiperparâmetros que utiliza o conceito de _bandas_ para otimizar o processo de busca. O algoritmo é baseado no conceito de _successive halving_, que consiste em treinar um modelo com um número de épocas e, a cada iteração, descartar os piores modelos e treinar os melhores com um número de épocas maior. O Hyperband utiliza esse conceito para treinar diversos modelos com diferentes números de épocas e descartar os piores, até que reste apenas um modelo. O número de modelos treinados é definido pelo parâmetro `max_epochs`, que define o número máximo de épocas que um modelo pode ser treinado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=5,\n",
    "                     factor=3,\n",
    "                     directory='hyperband',\n",
    "                     project_name='tuner_tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 22s]\n",
      "val_accuracy: 0.8511666655540466\n",
      "\n",
      "Best val_accuracy So Far: 0.8770833611488342\n",
      "Total elapsed time: 00h 03m 53s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 192 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=5, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch\n",
    "O RandomSearch é um algoritmo de busca de hiperparâmetros que utiliza o conceito de busca aleatória para otimizar o processo de busca. O algoritmo consiste em treinar diversos modelos com diferentes hiperparâmetros, escolhidos aleatoriamente dentro de um intervalo definido pelo usuário. O número de modelos treinados é definido pelo parâmetro `max_trials`, que define o número máximo de modelos que serão treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='random_search',\n",
    "    project_name='tuner_tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 31s]\n",
      "val_accuracy: 0.8778333067893982\n",
      "\n",
      "Best val_accuracy So Far: 0.8785833120346069\n",
      "Total elapsed time: 00h 02m 51s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=5, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization\n",
    "A busca bayesiana é um algoritmo de busca de hiperparâmetros que utiliza o conceito de busca bayesiana para otimizar o processo de busca. O algoritmo consiste em treinar diversos modelos com diferentes hiperparâmetros, escolhidos de acordo com uma distribuição de probabilidade que é atualizada a cada iteração. O número de modelos treinados é definido pelo parâmetro `max_trials`, que define o número máximo de modelos que serão treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='bayesian_optimization',\n",
    "    project_name='tuner_tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 04m 11s]\n",
      "val_accuracy: 0.8696944316228231\n",
      "\n",
      "Best val_accuracy So Far: 0.882111112276713\n",
      "Total elapsed time: 00h 12m 20s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 160 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=5, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações\n",
    "- Existe ainda uma quinta classe de Tuner, chamada `Sklearn Tuner`. Ele é usado para implementar os tuners em modelos do Sklearn. Como não utilizamos modelos do Sklearn, não iremos abordá-lo aqui.\n",
    "- Uma confusão comum: o `max_trials` é o parâmetro que define o número máximo de modelos que serão treinados. O `max_epochs` é o parâmetro que define o número máximo de épocas que um modelo pode ser treinado. O `max_trials` é utilizado pelo RandomSearch e pela busca bayesiana, enquanto o `max_epochs` é utilizado pelo Hyperband. \n",
    "- Como sugestão: é interessante usar um modelo de Random Search para encontrar espaços de parâmetros interessantes. Depois, um Grid Search será útil se poucos parâmetros forem analisados. Se muitos parâmetros forem analisados, verificar todos por todas as épocas pode ser muito demorado, e o Hyperband será mais eficiente. O Bayesian Optimization é uma alternativa ao Random Search, mas é mais complexo e pode ser mais demorado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5442 - accuracy: 0.8113 - val_loss: 0.4274 - val_accuracy: 0.8503\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4039 - accuracy: 0.8569 - val_loss: 0.3919 - val_accuracy: 0.8593\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3629 - accuracy: 0.8691 - val_loss: 0.3880 - val_accuracy: 0.8633\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3398 - accuracy: 0.8763 - val_loss: 0.3639 - val_accuracy: 0.8684\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3171 - accuracy: 0.8836 - val_loss: 0.3503 - val_accuracy: 0.8757\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3033 - accuracy: 0.8887 - val_loss: 0.3361 - val_accuracy: 0.8777\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2907 - accuracy: 0.8911 - val_loss: 0.3298 - val_accuracy: 0.8817\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2824 - accuracy: 0.8953 - val_loss: 0.3316 - val_accuracy: 0.8820\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2708 - accuracy: 0.9007 - val_loss: 0.3275 - val_accuracy: 0.8847\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2631 - accuracy: 0.9022 - val_loss: 0.3409 - val_accuracy: 0.8777\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2563 - accuracy: 0.9053 - val_loss: 0.3222 - val_accuracy: 0.8891\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2479 - accuracy: 0.9075 - val_loss: 0.3436 - val_accuracy: 0.8810\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2429 - accuracy: 0.9089 - val_loss: 0.3259 - val_accuracy: 0.8866\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2355 - accuracy: 0.9124 - val_loss: 0.3381 - val_accuracy: 0.8861\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2317 - accuracy: 0.9143 - val_loss: 0.3241 - val_accuracy: 0.8880\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2264 - accuracy: 0.9150 - val_loss: 0.3280 - val_accuracy: 0.8892\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2209 - accuracy: 0.9174 - val_loss: 0.3293 - val_accuracy: 0.8898\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2134 - accuracy: 0.9197 - val_loss: 0.3322 - val_accuracy: 0.8870\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2122 - accuracy: 0.9196 - val_loss: 0.3493 - val_accuracy: 0.8817\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2069 - accuracy: 0.9232 - val_loss: 0.3463 - val_accuracy: 0.8883\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.3393 - val_accuracy: 0.8901\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1993 - accuracy: 0.9271 - val_loss: 0.3403 - val_accuracy: 0.8892\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1959 - accuracy: 0.9276 - val_loss: 0.3812 - val_accuracy: 0.8810\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1938 - accuracy: 0.9268 - val_loss: 0.3475 - val_accuracy: 0.8894\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1875 - accuracy: 0.9309 - val_loss: 0.3535 - val_accuracy: 0.8876\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1853 - accuracy: 0.9314 - val_loss: 0.3448 - val_accuracy: 0.8898\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1834 - accuracy: 0.9324 - val_loss: 0.3584 - val_accuracy: 0.8901\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1788 - accuracy: 0.9335 - val_loss: 0.3609 - val_accuracy: 0.8879\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1756 - accuracy: 0.9350 - val_loss: 0.3739 - val_accuracy: 0.8823\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1741 - accuracy: 0.9350 - val_loss: 0.3748 - val_accuracy: 0.8879\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1703 - accuracy: 0.9366 - val_loss: 0.3651 - val_accuracy: 0.8863\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1691 - accuracy: 0.9368 - val_loss: 0.3774 - val_accuracy: 0.8869\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1647 - accuracy: 0.9401 - val_loss: 0.3861 - val_accuracy: 0.8827\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1623 - accuracy: 0.9390 - val_loss: 0.3790 - val_accuracy: 0.8834\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1606 - accuracy: 0.9409 - val_loss: 0.4052 - val_accuracy: 0.8809\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1599 - accuracy: 0.9413 - val_loss: 0.3955 - val_accuracy: 0.8863\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1553 - accuracy: 0.9426 - val_loss: 0.3947 - val_accuracy: 0.8865\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1540 - accuracy: 0.9420 - val_loss: 0.3984 - val_accuracy: 0.8870\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9449 - val_loss: 0.4121 - val_accuracy: 0.8833\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9446 - val_loss: 0.4255 - val_accuracy: 0.8838\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1481 - accuracy: 0.9455 - val_loss: 0.4093 - val_accuracy: 0.8859\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1459 - accuracy: 0.9454 - val_loss: 0.4053 - val_accuracy: 0.8878\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1428 - accuracy: 0.9464 - val_loss: 0.4360 - val_accuracy: 0.8832\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1418 - accuracy: 0.9475 - val_loss: 0.4255 - val_accuracy: 0.8817\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1402 - accuracy: 0.9481 - val_loss: 0.4188 - val_accuracy: 0.8842\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1383 - accuracy: 0.9482 - val_loss: 0.4378 - val_accuracy: 0.8811\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1352 - accuracy: 0.9500 - val_loss: 0.4382 - val_accuracy: 0.8848\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1341 - accuracy: 0.9507 - val_loss: 0.4435 - val_accuracy: 0.8827\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1325 - accuracy: 0.9508 - val_loss: 0.4506 - val_accuracy: 0.8823\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1318 - accuracy: 0.9509 - val_loss: 0.4445 - val_accuracy: 0.8811\n",
      "Best epoch: 21\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Callbacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos diferentes de callbacks\n",
    "Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "\n",
    "`BackupAndRestore`: Callback to back up and restore the training state.\n",
    "\n",
    "`BaseLogger`: Callback that accumulates epoch averages of metrics.\n",
    "\n",
    "**`CSVLogger`: Callback that streams epoch results to a CSV file.**\n",
    "\n",
    "**`Callback`: Abstract base class used to build new callbacks.**\n",
    "\n",
    "`CallbackList`: Container abstracting a list of callbacks.\n",
    "\n",
    "**`EarlyStopping`: Stop training when a monitored metric has stopped improving.**\n",
    "\n",
    "`History`: Callback that records events into a History object.\n",
    "\n",
    "`LambdaCallback`: Callback for creating simple, custom callbacks on-the-fly.\n",
    "\n",
    "**`LearningRateScheduler`: Learning rate scheduler.**\n",
    "\n",
    "**`ModelCheckpoint`: Callback to save the Keras model or model weights at some frequency.**\n",
    "\n",
    "`ProgbarLogger`: Callback that prints metrics to stdout.\n",
    "\n",
    "**`ReduceLROnPlateau`: Reduce learning rate when a metric has stopped improving.**\n",
    "\n",
    "`RemoteMonitor`: Callback used to stream events to a server.\n",
    "\n",
    "`SidecarEvaluatorModelExport`: Callback to save the best Keras model.\n",
    "\n",
    "`TensorBoard`: Enable visualizations for TensorBoard.\n",
    "\n",
    "**`TerminateOnNaN`: Callback that terminates training when a NaN loss is encountered.**\n",
    "\n",
    "\n",
    "*Os callbacks em negrito são os que serão abordados aqui.*  \n",
    "*Os que não estão em negrito não abordam assuntos relevantes para nossos problemas - `RemoteMonitor` - abordam assuntos muito específicos que eu não domino - `TensorBoard` - ou não funcionam na versão mais atual do Tensorflow - `ProgbarLogger`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "optmizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optmizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "    'csvlogger_model.csv', separator=',', append=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3592 - accuracy: 0.8705 - val_loss: 0.3673 - val_accuracy: 0.8682\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3549 - accuracy: 0.8728 - val_loss: 0.3432 - val_accuracy: 0.8773\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3557 - accuracy: 0.8715 - val_loss: 0.3924 - val_accuracy: 0.8637\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3520 - accuracy: 0.8729 - val_loss: 0.4187 - val_accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8728 - val_loss: 0.3968 - val_accuracy: 0.8596\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3495 - accuracy: 0.8739 - val_loss: 0.4062 - val_accuracy: 0.8478\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3441 - accuracy: 0.8769 - val_loss: 0.4384 - val_accuracy: 0.8606\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3428 - accuracy: 0.8764 - val_loss: 0.4043 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3360 - accuracy: 0.8789 - val_loss: 0.4670 - val_accuracy: 0.8559\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3473 - accuracy: 0.8769 - val_loss: 0.4024 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26190989d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example callback that prints the epoch number after each epoch over the total number of epochs.\n",
    "class PrintEpochCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print(f'Epoch {epoch} finished', end='\\r')\n",
    "\n",
    "print_epoch_callback = PrintEpochCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22de639b510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[print_epoch_callback], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3186 - accuracy: 0.8862 - val_loss: 0.4344 - val_accuracy: 0.8547\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8858 - val_loss: 0.4950 - val_accuracy: 0.8660\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3198 - accuracy: 0.8858 - val_loss: 0.4884 - val_accuracy: 0.8572\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3087 - accuracy: 0.8874 - val_loss: 0.4182 - val_accuracy: 0.8660\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3118 - accuracy: 0.8884 - val_loss: 0.4351 - val_accuracy: 0.8687\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3115 - accuracy: 0.8871 - val_loss: 0.4551 - val_accuracy: 0.8603\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3086 - accuracy: 0.8890 - val_loss: 0.4417 - val_accuracy: 0.8565\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3179 - accuracy: 0.8872 - val_loss: 0.4391 - val_accuracy: 0.8662\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3120 - accuracy: 0.8888 - val_loss: 0.4372 - val_accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2619396fe90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=1000, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_shceduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1 * 10**(epoch / 20),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 1e-08.\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8953 - val_loss: 0.4372 - val_accuracy: 0.8648 - lr: 1.0000e-08\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 1.1220184543019634e-08.\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8953 - val_loss: 0.4372 - val_accuracy: 0.8648 - lr: 1.1220e-08\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 1.2589254117941673e-08.\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8953 - val_loss: 0.4372 - val_accuracy: 0.8648 - lr: 1.2589e-08\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 1.4125375446227544e-08.\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8953 - val_loss: 0.4372 - val_accuracy: 0.8648 - lr: 1.4125e-08\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 1.5848931924611136e-08.\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2783 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8648 - lr: 1.5849e-08\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 1.7782794100389228e-08.\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8648 - lr: 1.7783e-08\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 1.9952623149688796e-08.\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8647 - lr: 1.9953e-08\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 2.2387211385683395e-08.\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8647 - lr: 2.2387e-08\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 2.51188643150958e-08.\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8647 - lr: 2.5119e-08\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 2.8183829312644537e-08.\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8953 - val_loss: 0.4371 - val_accuracy: 0.8648 - lr: 2.8184e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26195fab7d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[learning_rate_shceduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_checkpoint',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2782 - accuracy: 0.8954 - val_loss: 0.4371 - val_accuracy: 0.8648\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8954 - val_loss: 0.4370 - val_accuracy: 0.8648\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8954 - val_loss: 0.4370 - val_accuracy: 0.8648\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8954 - val_loss: 0.4370 - val_accuracy: 0.8648\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8954 - val_loss: 0.4370 - val_accuracy: 0.8648\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8954 - val_loss: 0.4370 - val_accuracy: 0.8649\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2780 - accuracy: 0.8954 - val_loss: 0.4369 - val_accuracy: 0.8649\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2780 - accuracy: 0.8954 - val_loss: 0.4369 - val_accuracy: 0.8649\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2780 - accuracy: 0.8954 - val_loss: 0.4369 - val_accuracy: 0.8649\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2780 - accuracy: 0.8955 - val_loss: 0.4369 - val_accuracy: 0.8649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x261986a2a10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_LR_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2759 - accuracy: 0.8965 - val_loss: 0.4349 - val_accuracy: 0.8655 - lr: 2.8184e-08\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2759 - accuracy: 0.8965 - val_loss: 0.4349 - val_accuracy: 0.8655 - lr: 2.8184e-08\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2759 - accuracy: 0.8965 - val_loss: 0.4349 - val_accuracy: 0.8655 - lr: 2.8184e-08\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2759 - accuracy: 0.8966 - val_loss: 0.4349 - val_accuracy: 0.8656 - lr: 2.8184e-08\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4349 - val_accuracy: 0.8656 - lr: 2.8184e-08\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4349 - val_accuracy: 0.8656 - lr: 2.8184e-08\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4348 - val_accuracy: 0.8656 - lr: 2.8184e-08\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4348 - val_accuracy: 0.8656 - lr: 2.8184e-08\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4348 - val_accuracy: 0.8655 - lr: 2.8184e-08\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2758 - accuracy: 0.8966 - val_loss: 0.4348 - val_accuracy: 0.8655 - lr: 2.8184e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2619a929d10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[reduce_LR_on_plateau])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback: TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerra o treinamento se uma loss igual a NaN for encontrada\n",
    "terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma custom loss que retorna NaN\n",
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "  def call(self, y_true, y_pred):\n",
    "    return tf.math.log(y_pred)\n",
    "  \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "optmizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = CustomLoss()\n",
    "\n",
    "model.compile(optimizer=optmizer,\n",
    "                loss=loss,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Batch 0: Invalid loss, terminating training\n",
      "1500/1500 [==============================] - 1s 466us/step - loss: nan - accuracy: 0.0312 - val_loss: nan - val_accuracy: 0.0995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x261d8f4da50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_train, label_train, epochs=10, validation_split=0.2, callbacks=[terminate_on_nan])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
